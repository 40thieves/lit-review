# History of bibliometrics

The field of bibliometrics, sometimes scientometrics, has existed for many years and has created a set of methods to quantitatively analyse scientific and technological literature [Bibliometrics and Citation Analysis: From the Science Citation Index to Cybermetrics; De Bellis; 2009]. These metrics are most commonly used to measure the impact, or value, of the research in question. This impact ranking has a diverse set of applications, including assessment of an author's work. One of the most widely used methods is the Impact Factor, sometimes known as the Journal Impact Factor.  It was first proposed by Eugene Garfield in 1972, in his paper, _Citation Analysis As A Tool in Journal Evaluation_. The impact factor is calculated using the following algorithm:

![Impact Factor algorithm](img/impact-factor.png)

The _Journal Citation Reports_ is published annually by Thomson Reuters, listing all known journals and giving their impact factor, and other metrics for the current year. Neylon and Wu [Article-Level Metrics and the Evolution of Scientific Impact; Neylon & Wu, 2009] state that "most scientists … will point to the Thomson ISI Journal Impact Factor as an external and 'objective' measure for ranking the impact of specific journals and the individual articles within them".

Usage of the impact factor in ranking research other than journals has become more widespread. Increasingly, impact factor has become a proxy for measuring many diverse research outputs. These range from comparisons of international impact to individual article value [Cash for papers: putting a premium on publication; Fuyuno & Cyranoski; 2006]  [Nefarious Numbers; Arnold & Fowler; 2010]  [The History and Meaning of the Journal Impact Factor; Garfield; 2006]. Article value is calculated by proxy, by simply taking the impact factor from the journal it was published in. This has lead to ranking author value, by totalling the impact factor of each paper published.

Because of it's wide-ranging use, the impact factor has a strong influence on the scientific community. This has affected decisions on where to publish, whom to promote or hire, the success of grant applications, library decisions to purchase and renew journal subscriptions, researchers deciding where to publish, researchers choice on what to read and even salary bonuses [Show Me The Data; Rossner, Van Epps & Hill; 2007]  [Nefarious Numbers; Arnold & Fowler; 2010]. The Public Library of Science Medicine (PLoS Medicine) Editors report that "in some countries, government funding of entire institutions is dependent on the number of publications in journals with high impact factors" [It is time to find a better way to assess the scientific literature; The PLoS Medicine Editors; 2006]. 

In the UK, governmental assessment of Higher Education institutions have been conducted by the Research Assessment Exercise (RAE) since 1986. The exercise relied on the "subjective assessment of scientific publications by a panel of experts". Because of this, the RAE was time-consuming and expensive, costing the UK Government £12 million and universities an additional £47 million [The Assessment of Science: The Relative Merits of Post-Publication Review, the Impact Factor, and the Number of Citations; Eyre-Walker & Stoletzki; 2013]. In 2014, the RAE will be replaced by the Research Excellence Framework (REF). The REF will controversially provide more focus research impact, with 25% of the final grading going towards measurement of value [Humanities research threatened by demands for 'economic impact'; Shepherd; 2009]. Allen, Jones and Dolby believe that it is the impact factor's place as the key indicator of research progression that provides much of the rationale for the move to a more metrics-based successor [Looking for landmarks: the role of expert review and bibliometric analysis in evaluating scientific publication outputs; Allen, Jones & Dolby; 2009].

* h-index & other metrics (?)
* Historical use cases (?)
	* Live peer review
	* Filtering (linked to above)
	* Performance review
		* Funding
		* Tenure
* Forms of impact (?)

The field of bibliometrics, sometimes scientometrics, has existed for many years and has created a set of methods to quantitatively analyse scientific and technological literature [Bibliometrics and Citation Analysis: From the Science Citation Index to Cybermetrics; De Bellis; 2009]. These metrics are most commonly used to measure the impact, or value, of the research in question. This impact ranking has a diverse set of applications, including assessment of an author's work. One of the most widely used methods is the Impact Factor, sometimes known as the Journal Impact Factor.  It was first proposed by Eugene Garfield in 1972, in his paper, _Citation Analysis As A Tool in Journal Evaluation_. The impact factor is calculated using the following algorithm:

![Impact Factor algorithm](img/impact-factor.png)

The _Journal Citation Reports_ is published annually by Thomson Reuters, listing all known journals and giving their impact factor, and other metrics for the current year. Neylon and Wu [Article-Level Metrics and the Evolution of Scientific Impact; Neylon & Wu, 2009] state that "most scientists … will point to the Thomson ISI Journal Impact Factor as an external and 'objective' measure for ranking the impact of specific journals and the individual articles within them".

Usage of the impact factor in ranking research other than journals has become more widespread. Increasingly, impact factor has become a proxy for measuring many diverse research outputs. These range from comparisons of international impact to individual article value [Cash for papers: putting a premium on publication; Fuyuno & Cyranoski; 2006]  [Nefarious Numbers; Arnold & Fowler; 2010]  [The History and Meaning of the Journal Impact Factor; Garfield; 2006]. Article value is calculated by proxy, by simply taking the impact factor from the journal it was published in. This has lead to ranking author value, by totalling the impact factor of each paper published.

Because of it's wide-ranging use, the impact factor has a strong influence on the scientific community. This has affected decisions on where to publish, whom to promote or hire, the success of grant applications, library decisions to purchase and renew journal subscriptions, researchers deciding where to publish, researchers choice on what to read and even salary bonuses [Show Me The Data; Rossner, Van Epps & Hill; 2007]  [Nefarious Numbers; Arnold & Fowler; 2010]. The Public Library of Science Medicine (PLoS Medicine) Editors report that "in some countries, government funding of entire institutions is dependent on the number of publications in journals with high impact factors" [It is time to find a better way to assess the scientific literature; The PLoS Medicine Editors; 2006]. 

In the UK, governmental assessment of Higher Education institutions have been conducted by the Research Assessment Exercise (RAE) since 1986. The exercise relied on the "subjective assessment of scientific publications by a panel of experts". Because of this, the RAE was time-consuming and expensive, costing the UK Government £12 million and universities an additional £47 million [The Assessment of Science: The Relative Merits of Post-Publication Review, the Impact Factor, and the Number of Citations; Eyre-Walker & Stoletzki; 2013]. In 2014, the RAE will be replaced by the Research Excellence Framework (REF). The REF will controversially provide more focus research impact, with 25% of the final grading going towards measurement of value [Humanities research threatened by demands for 'economic impact'; Shepherd; 2009]. Allen, Jones and Dolby believe that it is the impact factor's place as the key indicator of research progression that provides much of the rationale for the move to a more metrics-based successor [Looking for landmarks: the role of expert review and bibliometric analysis in evaluating scientific publication outputs; Allen, Jones & Dolby; 2009].
