# What is altmetrics?

As alternative to traditional bibliometrics, the concept of altmetrics was developed in the late 2000s. Although there are many different definitions, altmetrics as a term has evolved over the years to an umbrella term for metrics that measure impact of web-based scholarly communications both qualitatively and quantitatively [Altmetrics Manifesto; Priem, Taraborelli, Groth &  Neylon; 2010]  [Thoughts from the Fishbowl: PLOS ALM Workshop 2013; Liu; 2003]  [As Scholarship Goes Digital, Academics Seek New Ways to Measure Their Impact; Howard; 2012]. Altmetrics, in contrast to the _journal_ impact factor, are primarily measured at the article level, although it has been suggested by some that altmetrics should also measure impact outside of the traditional article [Article Level Metrics and the Evolution of Scientific Impact; Neylon & Wu; 2009]. Article level metrics is a term somewhat favoured initially by those looking for an alternative to the impact factor. However article level metrics have started to be incorporated under the banner of altmetrics [I like the term #articlelevelmetrics, but it fails to imply *diversity* of measures. Lately, I'm liking #altmetrics; Priem; 2010].

Metrics that have been included in altmetrics in the past include article views and downloads, scholarly tweets, bookmarks on bookmarking services like Delicious, saves on social referencing services like Mendeley and even traditional citations [Altmetrics in the Wild: Using Social Media to Explore Scholarly Impact; Priem, Piwowar, Hemminger; 2012]. There is a consensus that altmetrics are centre around mining web-based resources [As Scholarship Goes Digital, Academics Seek New Ways to Measure Their Impact; Howard; 2012]. There exists no definitive list of metric sources, and some disagree on the validity of specifics, but there is some movement towards standardising metrics and how they are measured [Do altmetrics work? Twitter and ten other social web services; Thelwall, Haustein, Lariviere et al; 2013]  [Altmetrics in Evolution: Defining and Redefining the Ontology of Article-Level Metrics; Liu & Fenner; 2013].

Kaitlin Thaney, Director of the Mozilla Science Lab, likened altmetrics to tracking "a researcher's footprints in the community" [Thoughts from the Fishbowl: PLOS ALM Workshop 2013; Liu; 2003]. A good metaphor for describing how altmetrics attempts to capture impact from a wide range of sources. It is this wide range of sources, and their relative ease of access that allows not only the measurement of scholarly communications, but also of the wider general public [Scientometrics 2.0; Priem & Hemminger; 2010]. Although the webometrics measurements have mined the web for impact data before, they have not updated for the rise of the social web, or Web 2.0. This new form of interaction on the web, enables a much larger audience to access publishing tools on the web. Users are using these tools to chat, discuss and share interesting links, activities that could potentially generate impact for researchers by measuring how far their research is spread [Altmetrics: impact, landscape, their value to the library; Galligan; 2012]. Priem & Hemminger state that "[the] emergence of 'Web 2.0' presents a new window through which to view the impact of scholarship" [Scientometrics 2.0; Priem & Hemminger; 2010].

The web's usage by scholars to communicate has been growing, and looks to continue into the future [Altmetrics Manifesto; Priem, Taraborelli, Groth & Neylon; 2010]. This usage comes in many forms, with studies finding usage on social media services, Twitter and Facebook [How and why people Twitter: the role that micro-blogging plays in informal communication at work; Zhao and Rosson; 2009], on blogs [Studying Scientific Discourse on the Web Using Bibliometrics: A Chemistry Blogging Case Study; Groth & Gurney; 2010], on bookmarking services, such as Delicious [Altmetrics in the Wild: Using Social Media to Explore Scholarly Impact; Priem, Piwowar, Hemminger; 2012], and social reference managers, such as Mendeley [The spread of scientific information: insights from the web usage statistics in PLoS article-level metrics; Yan & Gerstein; 2011]. Fenner found that 93% of PLOS Biology research articles published since June 2012 have been discussed on Twitter, and 63% mentioned on Facebook [What Can Article-Level Metrics Do for You?; Fenner; 2013].

* Usage of web for scholarly comms
	* Growth
		* "In growing numbers, scholars are moving their everyday work to the web"
		* "The use of social media discussion platforms, such as Twitter and Facebook for example, has increased in recent years"
			* "93% of PLOS Biology research articles published since June 2012 have been discussed on Twitter, and 63% mentioned on Facebook"
	* "New forms [of communication] reflect and transmit scholarly impact"
	* "[Scientific discourse] is not separate from traditional academic discourse in published papers, but is intertwined with it: blogs etc. are increasingly referring to, and commenting on, traditional publications."
	* "Twitter is increasingly used as a collaboration tool in work–related contexts"
* Diversity of metrics
	* "Scientific impact is a multi-dimensional construct that can not be adequately measured by any single indicator"
	* Clickstream model
		* Map of clicks as users move through system
		* Shows how impact cannot be simplified to a single number
* Metrics measured by altmetrics
	* "Tools [used by researchers] include social reference managers, Twitter, blogs, bookmarking services, and more"
	* Descriptions of services that generate metrics & their usage by scholars
		* User demographics (?)
			* "67% of bloggers in the sample were male, 18% female, 5% male-male, 4% male-female, 6% unknown"
		* Twitter
			* "Twitter is increasingly used as a collaboration tool in work–related contexts"
			* "Nearly 80% of the articles in the corpus reach the peak of Twitter mention just one day after they are submitted"
			* "Tweets can predict highly cited articles within the first 3 days of article publication"
			* "I would compare tweeting a scholarly article to bringing it up in a seminar or a classroom situation"
			* 52% directly linked to papers
			* 48% linked to a third-party, which then either linked to a paper or described a paper ("second-order links")
		* Blogs
			* "Many different motives behind science blogging"
			* Blogs in general are examples of participatory journalism, with scientific blogs primarily addressing issues and topics that are published in academic journals but also extending to scientific issues of interest to the public (e.g. global warming or health policy)
			* "Scientific discourse on the Web [referring to blogs] focuses on high quality science"
			* "Scientific discourse on the Web [again, blogs] includes the non-technical implications of science"
			* "The ability of blogs to present scientific research to a potential audience of non-academic but interested people is apparent"
		* Social bookmarking
		* Social reference managers
			* Mendeley
				* Broad adoption in life sciences, chemistry, math, computer science
				* 420m docs, increasing 1/2m a day
				* "[Mendeley often has] greater than 90% of recent issues of many journals"
				* API
					* Stats
						* "Number of Mendeley users who have a given document in their library" - "updated approximately daily"
				* Bought by Elsevier - relevant (?)
			* "Scientists collect the papers they find interesting, take notes on them, and store the information in a place that is accessible and useful to them"
			* "By broadcasting what papers they think are important, researchers are directly influencing the research community's choice of reading and discussion material"
			* "The user usually has the option of adding tags, comments, or ratings as part of the bookmarking process"
				* Metadata is valuable
		* Github
			* Code
		* Data
			* figshare
			* Dryad
	* ALMs
		* Views/downloads
		* Traditional citations (?)
* Categories of metrics
	* "We moved from an emphasis on the data source itself to the underlying activity captured by the data source"
		* By categorising metrics, we can capture the underlying intent in the metric
	* Concept of increasing engagement
		* Citing shows more engagement than a view/download
		* "When readers first see an interesting article, their response is often to view or download it. By contrast, a citation may be one of the last outcomes of their interest, occurring only about 1 in 300 times a PLOS paper is viewed online"
			* Doesn't however cover levels of access to more engaged metrics - i.e. not everyone can write a research paper in which to cite!
				* Could split, like ImpactStory does - into general public impact, and scholarly impact
					* "We suggest categorizing metrics along two axis: engagement type and audience"
	* Views/Downloads
	* Saved/Bookmarked
	* Shared/Recommended
	* Discussed
	* Formal citation
	* Hierarchy of metrics
		* Primary metrics: "includes the raw counts of activity captured by each source"
		* Secondary metrics: "comprised of descriptive statistics that give context to the primary metrics (e.g., article view to PDF download ratio and average usage of similar papers)"
* Existing altmetrics services
* Speed of altmetrics
	* Finds that "scientific discourse on the Web is more immediate" and that posts that discuss newer articles get more page views
* Timeline of usage
	* "The spread of a paper will then be reflected at the level of web usage statistics, in particular, the number of HTML views"
	* "On average, the older a paper is, the less attention it receives"
	* "In particular, from the first month to the second month, the decay is rapid, while later on the decay goes slower"
	* "After a scientist has accessed a paper (and hopefully read it as well), he/she might spread the information of the paper to his friends, colleagues or students. The information would then be further spread via a cascade of social interactions"
		* Follows simple stochastic model