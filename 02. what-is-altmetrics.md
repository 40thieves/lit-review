# What is altmetrics?

* Definition
	* Bit fuzzy
		* Some call it article level metrics 
			* "Instead of using "journal-level metrics" [the JIF], we use "article-level metrics" - metrics targeted at the specific article"
			* Some use that as a separate term to a wider definition of altmetrics
			* ALM seems to have evolved into altmetrics
			* "'Altmetrics' is the umbrella term for new ways (both qualitative and quantitative) of measuring different forms of impact"
			* "'Article-level metrics' has colloquially come to mean the altmetrics surrounding a scholarly paper, although technically it could include traditional bibliometrics, such as citations"
		* Many different definitions of altmetrics exist
		* All agree that it involves mining web-based scholarly resources
		* Some disagree on which resources
			* Some describe it as narrowly as "social reference managers"
			* Some include usage metrics
			* Others widen it even further to scraping scholarly blogs
			* (Opinion?) As the popularity of the term has increased, people have brought more under altmetrics' banner
	* First coined by Jason Priem:
		* "'Article-level metrics' didn’t completely cover what he felt should be conveyed [when he coined the term altmetrics]"
		* Instead wanted the term to convey "metrics of impact drawn from activity on online tools and environments"
	* "Suggested that altmetrics tracked 'a researcher’s footprint in the community'"
	* "The _scientific impact_ of a particular piece of research is reflected in how this work is taken up by the scientific community"
	* "Aims to measure Web-driven scholarly interactions, such as how research is tweeted, blogged about, or bookmarked"
	* "The Web can be mined for impact indicators"
		* Webometrics was here first
			* Didn't move to Web 2.0
		* "[The] emergence of 'Web 2.0' presents a new window through which to view the impact of scholarship"
	* "Altmetrics are new measurements for the impact of scholarly content, based on how far and wide it travels through the social Web, social bookmarking and collaboration tools … What altmetrics hope to do is provide an alternative measure of impact, distinct from the Journal Impact Factor"
* Usage of web for scholarly comms
	* Growth
		* "In growing numbers, scholars are moving their everyday work to the web"
		* "The use of social media discussion platforms, such as Twitter and Facebook for example, has increased in recent years"
			* "93% of PLOS Biology research articles published since June 2012 have been discussed on Twitter, and 63% mentioned on Facebook"
	* "New forms [of communication] reflect and transmit scholarly impact"
	* "[Scientific discourse] is not separate from traditional academic discourse in published papers, but is intertwined with it: blogs etc. are increasingly referring to, and commenting on, traditional publications."
	* "Twitter is increasingly used as a collaboration tool in work–related contexts"
* Diversity of metrics
	* "Scientific impact is a multi-dimensional construct that can not be adequately measured by any single indicator"
	* Clickstream model
		* Map of clicks as users move through system
		* Shows how impact cannot be simplified to a single number
* Metrics measured by altmetrics
	* "Tools [used by researchers] include social reference managers, Twitter, blogs, bookmarking services, and more"
	* Descriptions of services that generate metrics & their usage by scholars
		* User demographics (?)
			* "67% of bloggers in the sample were male, 18% female, 5% male-male, 4% male-female, 6% unknown"
		* Twitter
			* "Twitter is increasingly used as a collaboration tool in work–related contexts"
			* "Nearly 80% of the articles in the corpus reach the peak of Twitter mention just one day after they are submitted"
			* "Tweets can predict highly cited articles within the first 3 days of article publication"
			* "I would compare tweeting a scholarly article to bringing it up in a seminar or a classroom situation"
			* 52% directly linked to papers
			* 48% linked to a third-party, which then either linked to a paper or described a paper ("second-order links")
		* Blogs
			* "Many different motives behind science blogging"
			* Blogs in general are examples of participatory journalism, with scientific blogs primarily addressing issues and topics that are published in academic journals but also extending to scientific issues of interest to the public (e.g. global warming or health policy)
			* "Scientific discourse on the Web [referring to blogs] focuses on high quality science"
			* "Scientific discourse on the Web [again, blogs] includes the non-technical implications of science"
			* "The ability of blogs to present scientific research to a potential audience of non-academic but interested people is apparent"
		* Social bookmarking
		* Social reference managers
			* Mendeley
				* Broad adoption in life sciences, chemistry, math, computer science
				* 420m docs, increasing 1/2m a day
				* "[Mendeley often has] greater than 90% of recent issues of many journals"
				* API
					* Stats
						* "Number of Mendeley users who have a given document in their library" - "updated approximately daily"
				* Bought by Elsevier - relevant (?)
			* "Scientists collect the papers they find interesting, take notes on them, and store the information in a place that is accessible and useful to them"
			* "By broadcasting what papers they think are important, researchers are directly influencing the research community's choice of reading and discussion material"
			* "The user usually has the option of adding tags, comments, or ratings as part of the bookmarking process"
				* Metadata is valuable
		* Github
			* Code
		* Data
			* figshare
			* Dryad
	* ALMs
		* Views/downloads
		* Traditional citations (?)
* Categories of metrics
	* "We moved from an emphasis on the data source itself to the underlying activity captured by the data source"
		* By categorising metrics, we can capture the underlying intent in the metric
	* Concept of increasing engagement
		* Citing shows more engagement than a view/download
		* "When readers first see an interesting article, their response is often to view or download it. By contrast, a citation may be one of the last outcomes of their interest, occurring only about 1 in 300 times a PLOS paper is viewed online"
			* Doesn't however cover levels of access to more engaged metrics - i.e. not everyone can write a research paper in which to cite!
				* Could split, like ImpactStory does - into general public impact, and scholarly impact
					* "We suggest categorizing metrics along two axis: engagement type and audience"
	* Views/Downloads
	* Saved/Bookmarked
	* Shared/Recommended
	* Discussed
	* Formal citation
	* Hierarchy of metrics
		* Primary metrics: "includes the raw counts of activity captured by each source"
		* Secondary metrics: "comprised of descriptive statistics that give context to the primary metrics (e.g., article view to PDF download ratio and average usage of similar papers)"
* Existing altmetrics services
* Speed of altmetrics
	* Finds that "scientific discourse on the Web is more immediate" and that posts that discuss newer articles get more page views
* Timeline of usage
	* "The spread of a paper will then be reflected at the level of web usage statistics, in particular, the number of HTML views"
	* "On average, the older a paper is, the less attention it receives"
	* "In particular, from the first month to the second month, the decay is rapid, while later on the decay goes slower"
	* "After a scientist has accessed a paper (and hopefully read it as well), he/she might spread the information of the paper to his friends, colleagues or students. The information would then be further spread via a cascade of social interactions"
		* Follows simple stochastic model