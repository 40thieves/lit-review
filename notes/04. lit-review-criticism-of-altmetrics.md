
# Final Year Project
### Lit Review - Criticism of altmetrics

* [Soft Peer Review - Taraborelli](http://discovery.ucl.ac.uk/8279/1/8279.pdf)
	* Usage metrics
		* "It is debatable whether they will be able to overcome the major issues that afflicted search engine research over the last decade, which led it to abandon raw traffic data in favour of more accurate, scalable and spam-resistant criteria for quality assessment"
	* Social reference managers
		* "Cannot offer the same guarantees as standard selection processes (insofar as they do not rely on experts’ reviews and are less immune to biases and manipulations)"
* [Article Level Metrics and the Evolution of Scientific Impact](http://www.plosbiology.org/article/info:doi/10.1371/journal.pbio.1000242)
	* Usage factors (download numbers)
		* "A more important criticism of download statistics is that it is a crude measure of actual use"
		* "What we actually want to measure is how much influence an article has, not how many people clicked on the download button thinking they 'might read it later.'"
* [Scientometrics 2.0; Priem & Hemminger](http://firstmonday.org/ojs/index.php/fm/article/view/2874/2570)
	* History suggests that while gaming social metrics may not be solved, it can be controlled
	* Cites [Detecting spam web pages through content analysis; Ntoulas, et al.; 2006](http://dl.acm.org/citation.cfm?id=1135794)
		* "Advertisers have assaulted Google search results with 'black–hat SEO'"
	* Cites [Detecting spam in a Twitter network; Yardi et al; 2009](http://firstmonday.org/ojs/index.php/fm/article/view/2793/2431)
		* "[Finds] the existence of structural network differences between spam accounts and legitimate users"
	* "The Web is an inherently biased sample"
		* "Users of social software probably skew younger, and from more technical and scientific disciplines"
	* "Positive feedback created by these social tools [can be dangerous]: more popular items attract more attention, increasing their popularity still further"
	* "The social nature of these tools suggests that this may be of particular importance, especially given the stakes in big–money fields like pharmaceutical research"
		* Cites [Article level metrics; Dunckley; 2010](http://journalology.blogspot.co.uk/2010/02/article-level-metrics.html)
* [Do altmetrics work? Twitter and ten other social web services; Thelwall, Haustein, Lariviere et al; 2013](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0064841)
	* "Compares 11 altmetrics [i.e. web services] with Web of Science citations [i.e. impact factor	]"
	* "Tweets, Facebook wall posts, research highlights, blog mentions, mainstream media mentions and forum posts … may only be useful to identify the occasional exceptional or above average article rather than as universal sources of evidence"
	* "The coverage of the altmetrics, and particularly those other than Twitter, may be low"
		* Many cases where articles had no altmetrics associated with them - no tweets, Facebook mentions, etc
	* "A low coverage in combination with statistically significant results for an altmetric suggests that it is not useful to differentiate between average articles but may only be useful for identifying either exception articles or a sample of above average articles"
	* "Because of the increasing use of the social web, and Twitter in particular, publishers should consider ranking or displaying results in such a way that older articles are compensated for lower altmetric scores due to the lower social web use when they were published"
		* "More recent articles with the same eventual impact as older articles will tend to have much higher altmetric scores"
		* "In practice, this may not be a significant worry, however, because those searching the academic literature may prefer to find more recent articles"
* [Altmetrics in the Wild: Using Social Media to Explore Scholarly Impact; Priem, Piwowar, Hemminger; 2012](http://arxiv.org/abs/1203.4745)
	* "Scholarly use of social media [is] relatively rare, but significant and growing"
	* Cites [Studying Scientific Discourse on the Web using Bibliometrics: A Chemistry Blogging Case Study; Groth & Gurney; 2010](http://journal.webscience.org/308/2/websci10_submission_48.pdf)
		* "While discussions in scholarly blogs pull from diverse sources, they tend to focus on articles published in highly-cited journals"
	* "Several studies have compared traditional citation with usage or bookmarking in social reference managers, suggesting weak to moderate correlation"
		* Cites [Validating online reference managers for scholarly impact measurement; Li, Thelwall, Giustini; 2011](http://basie.exp.sis.pitt.edu/~christomer/lis2600/readings/li_validating.pdf)
			* "Correlations of `.56` and `.54`"
	* "For the top 100 most-tweeted articles in a sample from arXiv repository, log of tweet counts correlates weakly with log of citation counts"
	* "Additional research is needed before altmetrics can be relied upon in high-stakes evaluation like tenure and promotion decisions"
* [NISO ALM standardisation workshop; Mulvany; 2013](http://partiallyattended.com/2013/10/16/niso-alm-standardisation/)
	* His notes on the discussion around ALM standardisation - should ALM vendors adopt standards?
	* Notes that ImpactStory/Plumb Analytics were against, as it might cause calcification
	* His view: supports adopting best practices, perhaps not standards
* [The Assessment of Science: The Relative Merits of Post-Publication Review, the Impact Factor, and the Number of Citations; Eyre-Walker & Stoletzki; 2013](http://www.plosbiology.org/article/info%253Adoi%252F10.1371%252Fjournal.pbio.1001675)
	* "We have shown that scientists are poor at estimating the merit of a scientific publication; their assessments are error prone and biased by the journal in which the paper is published"
		* "[Expert] assessors give higher scores to papers in high IF journals (or underrate the science in low IF journals), independent of their merit"
	* Is it possible for altmetrics to avoid this bias?
* [Article-Level Metrics: An Ill-Conceived and Meretricious Idea; Beall; 2013](http://scholarlyoa.com/2013/08/01/article-level-metrics/)
	* The author imagines a world where "page views with be shamelessly gamed" by low wage workers hired to "reload web pages thousands of times"
	* "Previously-unknown researchers will suddenly boast more Twitter followers than Neil deGrasse Tyson because they will pay companies to add bogus followers to their social media accounts, and these bogus followers will like and share their articles, actions that will be counted as part of the metrics"
	* "The general public lacks the credentials needed to judge or influence the impact of scientific work, and any metric that relies even a little bit on public input will prove invalid"
		* Doesn't address concept of weighting metrics in favour of scholarly communication
		* Also doesn't address the concept of wider impact - very insular
* [New perspectives on article-level metrics: developing ways to assess research uptake and impact online; Liu & Adie; 2013](http://uksg.metapress.com/content/x65747080803n616/?genre=article&id=doi%253a10.1629%252f2048-7754.79)
	* "Altmetrics measures are not standardized and have not been systematically validated"
	* "There has been no clear consensus on which data sources are most important to measure"
	* "Technical limitations currently prevent the tracking of certain sources, such as multimedia files"
	* "It is the fact that online communication channels are populated by content from members of the public, as well as scholars, which has generated some scepticism towards the value of altmetrics"
		* "Such concerns are understandable, especially when one examines some of the trending articles that have garnered extremely high scores of online attention"
		* "Many of the articles that have gone viral are humorous, unusual, or even fictitious in nature; others frequently pertain to specific topics that are strongly emphasized in mainstream media"
* [Consuming Article-Level Metrics: Observations and Lessons; Chamberlain; 2013](http://www.niso.org/publications/isq/2013/v25no2/chamberlain/)
	* Brings up consistency of data between altmetrics/ALM providers
		* Especially on Twitter data
		* "Twitter data is notorious for not being persistent"
		* "Either have to query the Twitter 'firehose' constantly and store data, or go through a company like Topsy (which collects Twitter data and charges customers for access) to collect tweets"
		* "ImpactStory collects tweets from Topsy, PLOS collects tweets from the Twitter firehose, and Altmetric collects tweets using a combination of the Twitter search and streaming APIs"
		* "When similar data sources are collected by article-level metrics providers, ideally, there should be a way to [compare] data"
		* "ImpactStory provides a field named `provenance_url` with each metric data source"
			* PLoS ALM API provides a `events_url`, which is similar
			* Plum Analytics: "collect[s] alias URLs for each object for which they collect metrics"
				* "For example, for the DOI 10.1371/journal.pone.0018657, they collect many URLs that point to that paper"
				* "This makes sense as a digital product is inevitably going to end up living at more than one URL"
	* Historical ALM data
		* "PLOS provides historical article-level metrics data on some of their metrics"
		* "Altmetric provides publicly available historical data on their Altmetric score"
		* "ImpactStory and Plum Analytics do not provide historical data"
		* "As more [sources] are tracked, historical data will become expensive to store, so perhaps won’t be emphasized by article-level metrics providers."
	* "Many article-level metrics sources are accessible as the data providers have open, or at least partly open, APIs (e.g., PLoS). Other data sources are problematic"
		* "For example, you can only get tweets from Twitter for the past 30 days, after which you have to pay for a service that caches historical Twitter data (e.g., Topsy)"
		* "Other sources are totally inaccessible (e.g., Google Scholar citations)"
	* "Some metrics of interest may only be in PDFs, spreadsheets, or HTML, which cannot be easily machine-consumed and re-used or mashed up"
* [Exploring the Boundaries: How Altmetrics Can Expand Our Vision of Scholarly Communication and Social Impact; Taylor; 2013](http://www.niso.org/publications/isq/2013/v25no2/taylor/)
	* No impact measures currently capturing all forms of credit
		* "Although scholarly books are largely online and it is technically possible to mine books for citations to journals, it hasn’t hitherto been the practice of the bibliographic experts to include the various book citation figures"
		* "There are numerous locations where research articles are cited beyond other research articles: government reports, professional institutions’ guidelines for best practice, and press releases, to mention a few"
		* Other sources might include "massive online open courses (MOOCs), coursepacks, and reading lists"
		* "Although it is important to stress that there is no assumption that a citation in a MOOC has an equivalence to a citation in an article"
	* "There is a great deal of difficulty in distinguishing the role of published advice [to politicians]"
		* Has a large impact on society - informs medical policy
	* "The pathway from published research to social impact is multi-factorial and complex"
	* "A greater insight into how people work with research and how research reaches its impact at a human level is more within the scope of the humanities than computer science"
		* "Without the mutual engagement of the humanities and altmetrics, the analytical part of altmetrics will only ever be a limited proxy for social impact"
		* I disagree - misunderstanding of CS, as a core part of CS is to understand a complex system and a simple essence
* [Social Signals Reflect Academic Impact: What it Means When a Scholar Adds a Paper to Mendeley; Gunn; 2013](http://www.niso.org/publications/isq/2013/v25no2/gunn/)
	* "[It is] reasonable to expect altmetrics to favor recent papers"
* [Altmetrics: Rethinking the Way We Measure; Galligan & Dyas-Correia; 2013](http://www.sciencedirect.com/science/article/pii/S009879131300004X)
	* "With altmetrics, there is a sense that the users themselves should articulate how the measurements should be applied to specific problems, rather than dictated by an organization that thinks it knows best. This is the main drawback of all altmetric tools—there is as yet no simple way to interpret the data and give clear meaning"
	* _In response to criticism_:
		* "The sheer quantity of data that is available can help guard against people who might try to game the system since patterns can be detected with big data"
			* "It’s the same idea that underlies spam filters"
* [Can tweets predict citations? Metrics of social impact based on Twitter and correlation with traditional metrics of scientific impact; Eysenbach; 2011](http://www.jmir.org/2011/4/e123/)
	* "Using raw tweetation counts to compare the impact of different articles with each other is problematic, because the number of tweetations is a function of time since publication"
		* "The number of new tweetations drops off rapidly after publication, even for the most highly cited papers"
	* "It would not be legitimate to compare the twimpact factor of an article on social media with a twimpact factor of an article about molecular biology, and conclude that the social media article will be more likely cited"
		* Since articles about social media are more tweeted than articles about molecular biology, but won't necessarily get more citations, despite tweets being a resonable predictor for citations
	* "There is a real danger that research topics or findings that are not trendy enough to resonate with the Twitter population"
* [Can tweets predict citations? Metrics of social impact based on Twitter and correlation with traditional metrics of scientific impact; Eysenbach; 2011](http://www.jmir.org/2011/4/e123/)
	* "[Found[ that a large percentage of tweets were advertisements. This finding makes the use of Twitter as a communication tool challenging as advertisers can misuse it under the disguise of education"
* [Research blogs and the discussion of scholarly information; Shema, Bar-Ilan, Thelwall; 2012](http://www.plosone.org/article/info%253Adoi%252F10.1371%252Fjournal.pone.0035869)
	* "This could be viewed as the rich-get-richer phenomenon; papers in high impact journals get more attention in the scientific blogosphere"
		* "Another hypothesis is that since mainstream media often report on papers from high-ranking, reputable journals bloggers might focus on the same papers in order to offer their own analysis and interpretation"
	* "Blogs are dynamic by nature. They open, close, join a network or leave it, add authors or lose them at a rapid pace"