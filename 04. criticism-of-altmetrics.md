# Criticism of altmetrics

* Some data sources are inherently poor statistics
	* Usage metrics
		* "It is debatable whether they will be able to overcome the major issues that afflicted search engine research over the last decade, which led it to abandon raw traffic data in favour of more accurate, scalable and spam-resistant criteria for quality assessment" (Soft peer review: social software and distributed scientific evaluation; Taraborelli; 2008)
			* Vulnerable to spam, gaming
			* Network effects may go some way to solve this
				* Not investigated yet
		* Crude
			* "A more important criticism of download statistics is that it is a crude measure of actual use" (Article Level Metrics and the Evolution of Scientific Impact; Neylon & Wu; 2009)
			* "What we actually want to measure is how much influence an article has, not how many people clicked on the download button thinking they 'might read it later.'" (Article Level Metrics and the Evolution of Scientific Impact; Neylon & Wu; 2009)
	* Social reference managers
		* "Cannot offer the same guarantees as standard selection processes (insofar as they do not rely on experts’ reviews and are less immune to biases and manipulations)" (Soft peer review: social software and distributed scientific evaluation; Taraborelli; 2008)
	* "The coverage of the altmetrics, and particularly those other than Twitter, may be low" (Do altmetrics work? Twitter and ten other social web services; Thelwall, Haustein, Lariviere et al; 2013)
		* Many cases where articles had no altmetrics associated with them - no tweets, Facebook mentions, etc
	* "Scholarly use of social media [is] relatively rare, but significant and growing" (Altmetrics in the Wild: Using Social Media to Explore Scholarly Impact; Priem, Piwowar, Hemminger; 2012)
	* Priem, Piwowar & Hemminger cite (Studying Scientific Discourse on the Web using Bibliometrics: A Chemistry Blogging Case Study; Groth & Gurney; 2010) "While discussions in scholarly blogs pull from diverse sources, they tend to focus on articles published in highly-cited journals"
	* F1000
		* "We have shown that scientists are poor at estimating the merit of a scientific publication; their assessments are error prone and biased by the journal in which the paper is published" (The Assessment of Science: The Relative Merits of Post-Publication Review, the Impact Factor, and the Number of Citations; Eyre-Walker & Stoletzki; 2013)
			* [Expert] assessors give higher scores to papers in high IF journals (or underrate the science in low IF journals), independent of their merit"
		* Is it possible for altmetrics to avoid this bias
	* "Using raw tweetation counts to compare the impact of different articles with each other is problematic, because the number of tweetations is a function of time since publication" (Can tweets predict citations? Metrics of social impact based on Twitter and correlation with traditional metrics of scientific impact; Eysenbach; 2011)
		* "The number of new tweetations drops off rapidly after publication, even for the most highly cited papers"
		* "It would not be legitimate to compare the twimpact factor of an article on social media with a twimpact factor of an article about molecular biology, and conclude that the social media article will be more likely cited"
	* "[Found] that a large percentage of tweets were advertisements. This finding makes the use of Twitter as a communication tool challenging as advertisers can misuse it under the disguise of education" (Tweeting the meeting: an in-depth analysis of Twitter activity at Kidney Week 2011; Desai, Shariff, Shariff et al; 2012)
	* "This could be viewed as the rich-get-richer phenomenon; papers in high impact journals get more attention in the scientific blogosphere" (Research blogs and the discussion of scholarly information; Shema, Bar-Ilan, Thelwall; 2012)
		* "Another hypothesis is that since mainstream media often report on papers from high-ranking, reputable journals bloggers might focus on the same papers in order to offer their own analysis and interpretation"

* Evidence against correlation with citation
	* "Tweets, Facebook wall posts, research highlights, blog mentions, mainstream media mentions and forum posts … may only be useful to identify the occasional exceptional or above average article rather than as universal sources of evidence" (Do altmetrics work? Twitter and ten other social web services; Thelwall, Haustein, Lariviere et al; 2013)
		* "A low coverage in combination with statistically significant results for an altmetric suggests that it is not useful to differentiate between average articles but may only be useful for identifying either exception articles or a sample of above average articles"
		* "Because of the increasing use of the social web, and Twitter in particular, publishers should consider ranking or displaying results in such a way that older articles are compensated for lower altmetric scores due to the lower social web use when they were published"
		* "More recent articles with the same eventual impact as older articles will tend to have much higher altmetric scores"
		* "In practice, this may not be a significant worry, however, because those searching the academic literature may prefer to find more recent articles"
	* "Several studies have compared traditional citation with usage or bookmarking in social reference managers, suggesting weak to moderate correlation" (Altmetrics in the Wild: Using Social Media to Explore Scholarly Impact; Priem, Piwowar, Hemminger; 2012)
		* Cites [Validating online reference managers for scholarly impact measurement; Li, Thelwall, Giustini; 2011](http://basie.exp.sis.pitt.edu/~christomer/lis2600/readings/li_validating.pdf)
			* "Correlations of `.56` and `.54`"
		* "Many altmetric indicators seem mostly orthogonal to citation"
		* "For the top 100 most-tweeted articles in a sample from arXiv repository, log of tweet counts correlates weakly with log of citation counts"

* Gaming
	* The author imagines a world where "page views with be shamelessly gamed" by low wage workers hired to "reload web pages thousands of times" (Article-Level Metrics: An Ill-Conceived and Meretricious Idea; Beall; 2013)
		* "Previously-unknown researchers will suddenly boast more Twitter followers than Neil deGrasse Tyson because they will pay companies to add bogus followers to their social media accounts, and these bogus followers will like and share their articles, actions that will be counted as part of the metrics"
	* Can be controlled
		* "History suggests that while gaming social metrics may not be solved, it can be controlled" (Scientometrics 2.0; Priem & Hemminger; 2010)
			* Cites [Detecting spam web pages through content analysis; Ntoulas, et al.; 2006](http://dl.acm.org/citation.cfm?id=1135794) "Advertisers have assaulted Google search results with 'black–hat SEO'"
			* Cites [Detecting spam in a Twitter network; Yardi et al; 2009](http://firstmonday.org/ojs/index.php/fm/article/view/2793/2431) "[Finds] the existence of structural network differences between spam accounts and legitimate users"
			* "The social nature of these tools suggests that this may be of particular importance, especially given the stakes in big–money fields like pharmaceutical research" (Scientometrics 2.0; Priem & Hemminger; 2010)
				* Cites [Article level metrics; Dunckley; 2010](http://journalology.blogspot.co.uk/2010/02/article-level-metrics.html)
			* "The sheer quantity of data that is available can help guard against people who might try to game the system since patterns can be detected with big data" -> DOUBLE CHECK THIS IS A QUOTE
				* "It’s the same idea that underlies spam filters"
		* Scale probably helps
	* Google Scholar main shortcoming: "the ease with which they can be used to manipulate citation counting" (The Google scholar experiment: How to index false papers and manipulate bibliometric indicators; Delgado López-Cózar, Robinson-García & Torres-Salinas; 2013)
		* Criticises Google Scholar for being easy to game
		* Personally feel that this might not be a criticism of Google Scholar, but of the wider system
			* Fake papers were published, and no-one noticed
	* Spam

* Biased sample of people
	* "The Web is an inherently biased sample" (Scientometrics 2.0; Priem & Hemminger; 2010)
		* "Users of social software probably skew younger, and from more technical and scientific disciplines" (Scientometrics 2.0; Priem & Hemminger; 2010)
	* "Positive feedback created by these social tools [can be dangerous]: more popular items attract more attention, increasing their popularity still further" (Scientometrics 2.0; Priem & Hemminger; 2010)
	* "[It is] reasonable to expect altmetrics to favor recent papers" (Social Signals Reflect Academic Impact: What it Means When a Scholar Adds a Paper to Mendeley; Gunn; 2013)
	* "There is a real danger that research topics or findings that are not trendy enough to resonate with the Twitter population" (Can tweets predict citations? Metrics of social impact based on Twitter and correlation with traditional metrics of scientific impact; Eysenbach; 2011)

* Additional research required
	* "Additional research is needed before altmetrics can be relied upon in high-stakes evaluation like tenure and promotion decisions"

* Disagreement about standardisation
	* Notes that ImpactStory/Plumb Analytics were against, as it might cause "calcification" (NISO ALM standardisation workshop; Mulvany; 2013)
	* "Altmetrics measures are not standardized and have not been systematically validated" (New perspectives on article-level metrics: developing ways to assess research uptake and impact online; Liu & Adie; 2013)
		* "There has been no clear consensus on which data sources are most important to measure"
	* Brings up consistency of data between altmetrics/ALM providers (Consuming Article-Level Metrics: Observations and Lessons; Chamberlain; 2013)
		* Especially on Twitter data
		* "When similar data sources are collected by article-level metrics providers, ideally, there should be a way to [compare] data"
			* "ImpactStory provides a field named `provenance_url` with each metric data source"
	* No impact measures currently capturing all forms of credit (Exploring the Boundaries: How Altmetrics Can Expand Our Vision of Scholarly Communication and Social Impact; Taylor; 2013)
		* "Although scholarly books are largely online and it is technically possible to mine books for citations to journals, it hasn’t hitherto been the practice of the bibliographic experts to include the various book citation figures"
		* "There are numerous locations where research articles are cited beyond other research articles: government reports, professional institutions’ guidelines for best practice, and press releases, to mention a few"

* Technical issues with tracking
	* Twitter
		* "Twitter data is notorious for not being persistent" (Consuming Article-Level Metrics: Observations and Lessons; Chamberlain; 2013)
			* "Either have to query the Twitter 'firehose' constantly and store data, or go through a company like Topsy (which collects Twitter data and charges customers for access) to collect tweets"
	* Broken links
	* "Technical limitations currently prevent the tracking of certain sources, such as multimedia files" (New perspectives on article-level metrics: developing ways to assess research uptake and impact online; Liu & Adie; 2013)
	* "Other sources are totally inaccessible (e.g., Google Scholar citations)" (Consuming Article-Level Metrics: Observations and Lessons; Chamberlain; 2013)
	* "Some metrics of interest may only be in PDFs, spreadsheets, or HTML, which cannot be easily machine-consumed and re-used or mashed up" (Consuming Article-Level Metrics: Observations and Lessons; Chamberlain; 2013)

* Involving the public
	* "It is the fact that online communication channels are populated by content from members of the public, as well as scholars, which has generated some scepticism towards the value of altmetrics" (New perspectives on article-level metrics: developing ways to assess research uptake and impact online; Liu & Adie; 2013)
		* "Such concerns are understandable, especially when one examines some of the trending articles that have garnered extremely high scores of online attention"
		* "Many of the articles that have gone viral are humorous, unusual, or even fictitious in nature; others frequently pertain to specific topics that are strongly emphasized in mainstream media"
	* "The general public lacks the credentials needed to judge or influence the impact of scientific work, and any metric that relies even a little bit on public input will prove invalid" (Article-Level Metrics: An Ill-Conceived and Meretricious Idea; Beall; 2013)
			* Doesn't address concept of weighting metrics in favour of scholarly communication
			* Also doesn't address the concept of wider impact - very insular

* Hard to measure some forms of impact
	* "There is a great deal of difficulty in distinguishing the role of published advice [to politicians]" (Exploring the Boundaries: How Altmetrics Can Expand Our Vision of Scholarly Communication and Social Impact; Taylor; 2013)
	* "The pathway from published research to social impact is multi-factorial and complex" (Exploring the Boundaries: How Altmetrics Can Expand Our Vision of Scholarly Communication and Social Impact; Taylor; 2013)
		* "A greater insight into how people work with research and how research reaches its impact at a human level is more within the scope of the humanities than computer science"
		* I disagree - misunderstanding of CS, as a core part of CS is to understand a complex system and a simple essence